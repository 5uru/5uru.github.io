<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Calcul Vectoriel: Fondements Essentiels pour le Machine Learning</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
<header>
    <h1>Jonathan Suru</h1>
    <nav>
        <a href="../index.html">Accueil</a> |
        <a href="../projects.html">Projets</a> |
        <a href="../about.html">À propos</a>
    </nav>
</header>

<h1>Calcul Vectoriel : Fondements Essentiels pour le Machine Learning</h1>


<p>Cet article fait suite à notre précédent article <a href="dli25_linear_algebra.html">"Algèbre Linéaire : Fondements Essentiels pour le Machine Learning"</a>. Si l'algèbre linéaire nous a fourni le langage pour décrire <em>où</em> vivent les vecteurs et les matrices, le calcul vectoriel nous explique <em>comment</em> les fonctions transforment ces espaces - comment les quantités changent lorsque nous nous déplaçons.</p>

<p>Cet article s'inspire principalement d'une présentation issue du Deep Learning Indaba 2025 qui s'est tenu au Rwanda, organisée par Dr. Ismaila SECK, Géraud Nangue Tasse et l'équipe DLI. Comme indiqué dans leur présentation : "L'algèbre linéaire nous a donné le langage de là où vivent les vecteurs. Le calcul vectoriel nous dit comment les fonctions sculptent ces espaces - comment les quantités changent lorsque nous nous déplaçons."</p>

<p>Dans le domaine de l'apprentissage automatique, nous optimisons presque toujours une fonction de perte scalaire L(W) sur des millions de paramètres W. Comprendre le calcul vectoriel est donc essentiel pour maîtriser les algorithmes d'apprentissage automatique. Sans cette compréhension, il est difficile d'innover véritablement dans le domaine.</p>

<h2>1. Différentiation Scalaire \(f: \mathbb{R} \rightarrow \mathbb{R}\)</h2>
<p>La différentielle scalaire est le point de départ de notre exploration. Elle concerne les fonctions qui prennent un nombre réel en entrée et produisent un nombre réel en sortie.</p>

<h3>Définition de la dérivée</h3>
<p>La dérivée est définie comme la limite du quotient des différences :</p>
<p>$$ f'(x) = \frac{df}{dx} = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} $$</p>

<h3>Exemple :</h3>
<p>Prenons la fonction \(f(x) = x^2\). Calculons sa dérivée en utilisant la définition :</p>
<ol>
    <li>$$ f(x+h) = (x+h)^2 = x^2 + 2xh + h^2 $$</li>
    <li>$$ f(x+h) - f(x) = (x^2 + 2xh + h^2) - x^2 = 2xh + h^2 $$</li>
    <li>$$ \frac{f(x+h) - f(x)}{h} = \frac{2xh + h^2}{h} = 2x + h $$</li>
    <li>$$ \lim_{h \to 0} (2x + h) = 2x $$</li>
</ol>
<p>Donc, \(f'(x) = 2x\) pour \(f(x) = x^2\).</p>

<h3>Interprétation concrète : La vitesse comme dérivée de la position</h3>
<p>Considérons un objet en mouvement dont la position est décrite par une fonction de temps \(s(t)\).</p>
<ul>
    <li>Soit \(s(t) = 5t^2 + 2t + 1\) la position de l'objet en mètres à l'instant \(t\) (en secondes)</li>
    <li>La vitesse \(v(t)\) est la dérivée de la position par rapport au temps: \(v(t) = s'(t)\)</li>
</ul>

<h4>Calcul</h4>
<ul>
    <li>\(s(t) = 5t^2 + 2t + 1\)</li>
    <li>\(s'(t) = 10t + 2\) (en utilisant la règle de puissance: \((t^n)' = nt^{n-1}\))</li>
</ul>

<h4>Interprétation</h4>
<ul>
    <li>À \(t = 0\) s: \(s(0) = 1\) m et \(v(0) = 2\) m/s</li>
    <li>À \(t = 2\) s: \(s(2) = 5(2)^2 + 2(2) + 1 = 25\) m et \(v(2) = 10(2) + 2 = 22\) m/s</li>
</ul>

<h4>Signification physique</h4>
<ul>
    <li>La position \(s(t)\) indique où se trouve l'objet à chaque instant</li>
    <li>La vitesse \(v(t) = s'(t)\) indique à quelle vitesse et dans quelle direction l'objet se déplace</li>
    <li>Plus formellement, la vitesse instantanée est la limite du quotient des différences lorsque l'intervalle de temps tend vers zéro</li>
</ul>

<h4>Pourquoi c'est important pour le machine learning</h4>
<ul>
    <li>Ce concept de "taux de changement instantané" est directement applicable aux algorithmes d'optimisation</li>
    <li>Dans la descente de gradient, nous utilisons le gradient (généralisation de la dérivée) pour déterminer dans quelle direction et à quelle vitesse "descendre" la surface de perte</li>
    <li>Comprendre ce concept de base nous aide à visualiser pourquoi la descente de gradient fonctionne</li>
</ul>

<h3>Règles de base de différentielle</h3>

<h4>Règle de somme</h4>
<p>$$ (f(x)+g(x))' = f'(x)+g'(x) = \frac{df(x)}{dx} + \frac{dg(x)}{dx} $$</p>

<h5>Exemple</h5>
<ul>
    <li>\(f(x) = x^2 + 3x\)</li>
    <li>\(f'(x) = (x^2)' + (3x)' = 2x + 3\)</li>
</ul>


<h4>Règle de produit</h4>
<p>$$ (f(x)g(x))' = f'(x)g(x) + f(x)g'(x) = \frac{df(x)}{dx}g(x) + f(x)\frac{dg(x)}{dx} $$</p>

<h5>Exemple</h5>
<ul>
    <li>\(f(x) = x^2 \cdot x = x^3\)</li>
    <li>\(f'(x) = (x^2)' \cdot x + x^2 \cdot (x)' = 2x \cdot x + x^2 \cdot 1 = 2x^2 + x^2 = 3x^2\)</li>
    <li>Ce qui est correct car nous savons que \((x^3)' = 3x^2\)</li>
</ul>

<h4>Règle de chaîne</h4>
<p>$$ (g \circ f)'(x) = (g(f(x)))' = g'(f(x))f'(x) = \frac{dg(f(x))}{df} \frac{df(x)}{dx} $$</p>

<h5>Exemple très simple pour débutants</h5>
<ul>
    <li>\(g(z) = z^2\) et \(z = f(x) = 2x\)</li>
    <li>\(g(f(x)) = (2x)^2 = 4x^2\)</li>
    <li>Dérivée directe : \((4x^2)' = 8x\)</li>
    <li>Avec la règle de chaîne : \(g'(z) = 2z\) et \(f'(x) = 2\)</li>
    <li>Donc : \(g'(f(x)) \cdot f'(x) = 2(2x) \cdot 2 = 4x \cdot 2 = 8x\)</li>
</ul>

<h5>Interprétation</h5>
<p>La règle de chaîne est comme une "chaîne" de dérivées. Si vous avez une fonction à l'intérieur d'une autre fonction, vous devez multiplier les dérivées.</p>

<h3>Application pratique en apprentissage automatique</h3>

<h4>Exemple concret</h4>
<p>Considérons une fonction sigmoïde utilisée dans les réseaux de neurones :</p>
<ul>
    <li>\(\sigma(z) = \frac{1}{1 + e^{-z}}\)</li>
    <li>Calculons sa dérivée \(\sigma'(z)\) :</li>
    <li>\(\sigma(z) = (1 + e^{-z})^{-1}\)</li>
    <li>\(\sigma'(z) = -1 \cdot (1 + e^{-z})^{-2} \cdot (-e^{-z})\)</li>
    <li>\(\sigma'(z) = \frac{e^{-z}}{(1 + e^{-z})^2}\)</li>
    <li>\(\sigma'(z) = \frac{1}{1 + e^{-z}} \cdot \frac{e^{-z}}{1 + e^{-z}}\)</li>
    <li>\(\sigma'(z) = \sigma(z) \cdot (1 - \sigma(z))\)</li>
</ul>

<h4>Pourquoi c'est important</h4>
<p>Cette dérivée simple est utilisée partout dans les réseaux de neurones pour la rétropropagation. Si vous comprenez cela, vous comprenez déjà une grande partie du fonctionnement des réseaux de neurones!</p>

<h2>2. Différentiation Multivariée \(f: \mathbb{R}^N \rightarrow \mathbb{R}\)</h2>
<p>Lorsque nous passons à des fonctions avec plusieurs variables d'entrée, nous entrons dans le domaine de la différentielle multivariée.</p>

<h3>Dérivées partielles</h3>
<p>La dérivée partielle mesure le taux de changement d'une fonction par rapport à une seule variable à la fois, en gardant toutes les autres variables constantes :</p>
<p>$$ \frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, ..., x_{i-1}, x_i+h, x_{i+1}, ..., x_N) - f(x)}{h} $$</p>

<h3>Le gradient</h3>
<p>Le gradient est un vecteur qui regroupe toutes les dérivées partielles d'une fonction scalaire par rapport à chacune de ses variables d'entrée :</p>
<p>\[\nabla f = \frac{df}{dx} = \left[\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_N}\right] \in \mathbb{R}^{1 \times N}\]</p>
<p>Notez que le gradient est un vecteur ligne dans cette notation.</p>

<h4>Interprétation géométrique</h4>
<p>Le gradient pointe dans la direction de la plus forte augmentation de la fonction. Sa magnitude indique le taux de cette augmentation.</p>

<h3>Exemple de différentielle multivariée</h3>

<h4>Fonction simple</h4>
<ul>
    <li>\(f(x_1, x_2) = x_1^2 x_2 + x_1^3\)</li>
    <li>\(\frac{\partial f(x_1, x_2)}{\partial x_1} = 2x_1 x_2 + 3x_1^2\)</li>
    <li>\(\frac{\partial f(x_1, x_2)}{\partial x_2} = x_1^2\)</li>
    <li>Gradient : $$ \frac{df}{dx} = [2x_1 x_2 + 3x_1^2, x_1^2] $$</li>
</ul>

<h4>Fonction avancée</h4>
<ul>
    <li>\(f(x_1, x_2) = (x_1 + 2x_2^3)^2\)</li>
    <li>\(\frac{\partial f(x_1, x_2)}{\partial x_1} = 2(x_1 + 2x_2^3) \cdot 1\)</li>
    <li>\(\frac{\partial f(x_1, x_2)}{\partial x_2} = 2(x_1 + 2x_2^3) \cdot 6x_2^2\)</li>
    <li>Gradient : \(\frac{df}{dx} = [2(x_1 + 2x_2^3), 12x_2^2(x_1 + 2x_2^3)]\)</li>
</ul>

<h2>3. Différentiation de Champs Vectoriels \(f: \mathbb{R}^N \rightarrow \mathbb{R}^M\)</h2>
<p>Lorsque notre fonction produit un vecteur en sortie plutôt qu'un scalaire, nous entrons dans le domaine de la différentielle de champs vectoriels.</p>

<h3>La matrice jacobienne</h3>
<p>La matrice jacobienne est la généralisation du gradient aux fonctions vectorielles. Elle regroupe toutes les dérivées partielles premières :</p>
<p>\[J = \frac{df}{dx} = \begin{bmatrix}
    \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_N} \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_M}{\partial x_1} & \cdots & \frac{\partial f_M}{\partial x_N}
    \end{bmatrix} \in \mathbb{R}^{M \times N}\]</p>
<p>Où \(J_{ij} = \frac{\partial f_i}{\partial x_j}\)</p>

<h4>Interprétation géométrique</h4>
<p>La matrice jacobienne \(J(x_0)\) représente la meilleure application linéaire qui approxime la fonction \(f\) près du point \(x_0\).</p>

<h3>Exemple important : Transformation linéaire</h3>
<p>Considérons \(f(x) = Ax\), où \(f(x) \in \mathbb{R}^M\), \(A \in \mathbb{R}^{M \times N}\) et \(x \in \mathbb{R}^N\) :</p>
<p>\[\begin{bmatrix}
    y_1 \\
    \vdots \\
    y_M
    \end{bmatrix}
    =
    \begin{bmatrix}
    f_1(x) \\
    \vdots \\
    f_M(x)
    \end{bmatrix}
    =
    \begin{bmatrix}
    A_{11}x_1 + A_{12}x_2 + \cdots + A_{1N}x_N \\
    \vdots \\
    A_{M1}x_1 + A_{M2}x_2 + \cdots + A_{MN}x_N
    \end{bmatrix}\]</p>

<p>Le gradient est alors simplement :</p>
<p>\[\frac{df}{dx} =
    \begin{bmatrix}
    \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_N} \\
    \vdots & \ddots & \vdots \\
    \frac{\partial f_M}{\partial x_1} & \cdots & \frac{\partial f_M}{\partial x_N}
    \end{bmatrix}
    = A \in \mathbb{R}^{M \times N}\]</p>

<h3>Exemple d'application en apprentissage automatique</h3>
<p>Considérons la fonction de perte :</p>
<p>\[L(W) = \|e\|^2 = \|y - f(x, W)\|^2\]</p>
<p>Où \(f(x, W) = W^T x\), avec \(x \in \mathbb{R}^N\), \(y \in \mathbb{R}\), et \(W \in \mathbb{R}^{N \times M}\)</p>

<p>Pour calculer le gradient \(\frac{dL}{dW}\) :</p>
<ol>
    <li>\(L = e^T e\) où \(e = y - W^T x\)</li>
    <li>\(\frac{dL}{de} = 2e \in \mathbb{R}^M\)</li>
    <li>\(\frac{de}{dW} = -x^T \in \mathbb{R}^{M \times N}\)</li>
    <li>\(\frac{dL}{dW} = \frac{dL}{de} \cdot \frac{de}{dW} = 2e \cdot (-x^T) = -2(y - W^T x)x^T \in \mathbb{R}^{1 \times N}\)</li>
</ol>
<p>Notez que la dimension du gradient est : nombre de dimensions de la cible × nombre de dimensions d'entrée.</p>

<h2>4. La Règle de Chaîne et la Rétropropagation</h2>

<h3>Comprendre la Règle de Chaîne en Profondeur</h3>
<p>La règle de chaîne est l'outil mathématique le plus important pour comprendre la rétropropagation. Elle nous permet de calculer la dérivée d'une fonction composée, ce qui est essentiel dans les réseaux de neurones où les transformations s'empilent les unes sur les autres.</p>

<p>Pour deux fonctions \(f\) et \(g\), la règle de chaîne s'écrit :</p>
<p>\[(g \circ f)'(x) = g'(f(x)) \cdot f'(x)\]</p>

<p>Pour trois fonctions \(f\), \(g\) et \(h\) :</p>
<p>\[(h \circ g \circ f)'(x) = h'(g(f(x))) \cdot g'(f(x)) \cdot f'(x)\]</p>

<h4>Interprétation</h4>
<p>Le taux de changement global est le produit des taux de changement locaux à chaque étape de la composition.</p>

<h3>Diagramme de Rétropropagation dans un Réseau de Neurones</h3>

<div style="border: 1px solid black; padding: 10px; margin: 20px 0;">
    <h4>Réseau de neurones à une couche cachée</h4>

    <svg width="800" height="500" xmlns="http://www.w3.org/2000/svg">
        <!-- Définition des styles -->
        <defs>
            <marker id="arrowBlue" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                <path d="M0,0 L0,6 L9,3 z" fill="#0066cc"/>
            </marker>
            <marker id="arrowRed" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
                <path d="M0,0 L0,6 L9,3 z" fill="#cc0000"/>
            </marker>
        </defs>

        <!-- Couche d'entrée -->
        <circle cx="100" cy="150" r="20" fill="#f0f0f0" stroke="#000" stroke-width="2"/>
        <text x="100" y="155" text-anchor="middle" font-size="14">x₁</text>

        <circle cx="100" cy="250" r="20" fill="#f0f0f0" stroke="#000" stroke-width="2"/>
        <text x="100" y="255" text-anchor="middle" font-size="14">x₂</text>

        <!-- Couche cachée -->
        <circle cx="300" cy="100" r="25" fill="#d0e0ff" stroke="#000" stroke-width="2"/>
        <text x="300" y="105" text-anchor="middle" font-size="14">a₁⁽¹⁾</text>

        <circle cx="300" cy="300" r="25" fill="#d0e0ff" stroke="#000" stroke-width="2"/>
        <text x="300" y="305" text-anchor="middle" font-size="14">a₂⁽¹⁾</text>

        <!-- Couche de sortie -->
        <circle cx="500" cy="200" r="25" fill="#ffe0d0" stroke="#000" stroke-width="2"/>
        <text x="500" y="205" text-anchor="middle" font-size="14">ŷ</text>

        <!-- Cible -->
        <circle cx="650" cy="200" r="20" fill="#f0f0f0" stroke="#000" stroke-width="2" stroke-dasharray="5,5"/>
        <text x="650" y="205" text-anchor="middle" font-size="14">y</text>

        <!-- Connexions propagation avant (flèches bleues) -->
        <line x1="120" y1="150" x2="275" y2="100" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="120" y1="150" x2="275" y2="300" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="120" y1="250" x2="275" y2="100" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="120" y1="250" x2="275" y2="300" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="325" y1="100" x2="475" y2="200" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="325" y1="300" x2="475" y2="200" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>


        <line x1="525" y1="200" x2="630" y2="200" stroke="#0066cc" stroke-width="2" stroke-dasharray="5,5"/>
        <text x="580" y="190" fill="#0066cc" font-size="12">compare</text>

        <!-- Connexions rétropropagation (flèches rouges) -->
        <line x1="525" y1="220" x2="650" y2="220" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>
        <text x="580" y="240" fill="#cc0000" font-size="12">e = y - ŷ</text>

        <line x1="475" y1="210" x2="325" y2="110" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>


        <line x1="475" y1="210" x2="325" y2="310" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>


        <line x1="275" y1="110" x2="120" y2="160" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>


        <line x1="275" y1="110" x2="120" y2="260" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>


        <line x1="275" y1="310" x2="120" y2="160" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>


        <line x1="275" y1="310" x2="120" y2="260" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>



        <!-- Légende -->
        <rect x="600" y="320" width="180" height="100" fill="#f9f9f9" stroke="#000" stroke-width="1"/>
        <text x="610" y="340" font-size="14" font-weight="bold">Légende:</text>

        <line x1="610" y1="360" x2="640" y2="360" stroke="#0066cc" stroke-width="2" marker-end="url(#arrowBlue)"/>
        <text x="650" y="365" font-size="12">Propagation avant</text>

        <line x1="610" y1="390" x2="640" y2="390" stroke="#cc0000" stroke-width="2" marker-end="url(#arrowRed)"/>
        <text x="650" y="395" font-size="12">Rétropropagation</text>
    </svg>

    <p>Considérons un réseau de neurones simple avec :</p>
    <ul>
        <li>2 entrées (\(x_1, x_2\))</li>
        <li>2 neurones cachés</li>
        <li>1 sortie</li>
        <li>Fonction d'activation sigmoïde \(\sigma(z) = \frac{1}{1+e^{-z}}\)</li>
        <li>Fonction de perte quadratique \(L = \frac{1}{2}(y - \hat{y})^2\)</li>
    </ul>

    <h4>Notation</h4>
    <ul>
        <li>\(x = [x_1, x_2]^T\) : vecteur d'entrée</li>
        <li>\(W^{(1)}\) : poids de la couche d'entrée à la couche cachée (\(2 \times 2\))</li>
        <li>\(b^{(1)}\) : biais de la couche cachée (\(2 \times 1\))</li>
        <li>\(W^{(2)}\) : poids de la couche cachée à la sortie (\(1 \times 2\))</li>
        <li>\(b^{(2)}\) : biais de la sortie (\(1 \times 1\))</li>
        <li>\(z^{(1)} = W^{(1)}x + b^{(1)}\) : entrées de la couche cachée</li>
        <li>\(a^{(1)} = \sigma(z^{(1)})\) : sorties de la couche cachée</li>
        <li>\(z^{(2)} = W^{(2)}a^{(1)} + b^{(2)}\) : entrée de la couche de sortie</li>
        <li>\(\hat{y} = z^{(2)}\) : sortie du réseau (linéaire)</li>
        <li>\(L = \frac{1}{2}(y - \hat{y})^2\) : fonction de perte</li>
    </ul>
</div>



<h4>Étape 1: Propagation Avant</h4>
<p>La propagation avant calcule la sortie du réseau pour une entrée donnée.</p>

<h5>Calcul des valeurs de la couche cachée</h5>
<ul>
    <li>\(z^{(1)} = W^{(1)}x + b^{(1)} = \begin{bmatrix} w_{11}^{(1)} & w_{12}^{(1)} \\ w_{21}^{(1)} & w_{22}^{(1)} \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} + \begin{bmatrix} b_1^{(1)} \\ b_2^{(1)} \end{bmatrix}\)</li>
    <li>\(a^{(1)} = \sigma(z^{(1)}) = \begin{bmatrix} \sigma(z_1^{(1)}) \\ \sigma(z_2^{(1)}) \end{bmatrix}\)</li>
</ul>

<h5>Calcul de la sortie</h5>
<ul>
    <li>\(z^{(2)} = W^{(2)}a^{(1)} + b^{(2)} = [w_1^{(2)}, w_2^{(2)}] \begin{bmatrix} a_1^{(1)} \\ a_2^{(1)} \end{bmatrix} + b^{(2)}\)</li>
    <li>\(\hat{y} = z^{(2)}\)</li>
</ul>

<h4>Étape 2: Calcul de l'Erreur</h4>
<p>L'erreur mesure la différence entre la prédiction et la valeur réelle.</p>
<ul>
    <li>\(e = y - \hat{y}\)</li>
    <li>\(L = \frac{1}{2}e^2\)</li>
</ul>

<h4>Étape 3: Rétropropagation - Calcul des Deltas</h4>
<p>La rétropropagation calcule les erreurs "responsables" à chaque couche en appliquant la règle de chaîne.</p>

<h5>Calcul du delta de sortie (\(\delta^{(2)}\))</h5>
<ul>
    <li>\(\delta^{(2)} = \frac{\partial L}{\partial z^{(2)}} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z^{(2)}}\)</li>
    <li>\(\frac{\partial L}{\partial \hat{y}} = -(y - \hat{y}) = -e\)</li>
    <li>\(\frac{\partial \hat{y}}{\partial z^{(2)}} = 1\) (puisque \(\hat{y} = z^{(2)}\))</li>
    <li>Donc \(\delta^{(2)} = -e \cdot 1 = -(y - \hat{y})\)</li>
</ul>

<h5>Calcul du delta de la couche cachée (\(\delta^{(1)}\))</h5>
<ul>
    <li>\(\delta^{(1)} = \left((W^{(2)T} \cdot \delta^{(2)}) \odot \sigma'(z^{(1)})\right)\)</li>
    <li>\(W^{(2)T} \cdot \delta^{(2)}\) propage l'erreur de la sortie vers la couche cachée</li>
    <li>\(\sigma'(z^{(1)}) = \sigma(z^{(1)})(1 - \sigma(z^{(1)}))\) est la dérivée de la fonction d'activation</li>
    <li>L'opérateur \(\odot\) représente la multiplication élément par élément (Hadamard)</li>
</ul>

<h4>Étape 4: Calcul des Gradients</h4>

<h5>Gradient pour les poids de la couche de sortie</h5>
<p>\(\frac{\partial L}{\partial W^{(2)}} = \delta^{(2)} \cdot (a^{(1)})^T\)</p>

<h5>Gradient pour les biais de la couche de sortie</h5>
<p>\(\frac{\partial L}{\partial b^{(2)}} = \delta^{(2)}\)</p>

<h5>Gradient pour les poids de la couche cachée</h5>
<p>\(\frac{\partial L}{\partial W^{(1)}} = \delta^{(1)} \cdot x^T\)</p>

<h5>Gradient pour les biais de la couche cachée</h5>
<p>\(\frac{\partial L}{\partial b^{(1)}} = \delta^{(1)}\)</p>

<h4>Étape 5: Mise à Jour des Paramètres</h4>
<p>Les poids et biais sont mis à jour en utilisant les gradients calculés :</p>
<ul>
    <li>\(W^{(2)}_{nouveau} = W^{(2)}_{ancien} - \eta \cdot \frac{\partial L}{\partial W^{(2)}}\)</li>
    <li>\(b^{(2)}_{nouveau} = b^{(2)}_{ancien} - \eta \cdot \frac{\partial L}{\partial b^{(2)}}\)</li>
    <li>\(W^{(1)}_{nouveau} = W^{(1)}_{ancien} - \eta \cdot \frac{\partial L}{\partial W^{(1)}}\)</li>
    <li>\(b^{(1)}_{nouveau} = b^{(1)}_{ancien} - \eta \cdot \frac{\partial L}{\partial b^{(1)}}\)</li>
</ul>
<p>Où \(\eta\) est le taux d'apprentissage.</p>

<h4>Exemple Numérique Complet</h4>
<p>Prenons des valeurs numériques spécifiques :</p>
<ul>
    <li>\(x = [1, 2]^T\)</li>
    <li>\(W^{(1)} = \begin{bmatrix} 0.1 & 0.2 \\ 0.3 & 0.4 \end{bmatrix}\)</li>
    <li>\(b^{(1)} = \begin{bmatrix} 0.1 \\ 0.2 \end{bmatrix}\)</li>
    <li>\(W^{(2)} = [0.5, 0.6]\)</li>
    <li>\(b^{(2)} = 0.1\)</li>
    <li>\(y = 1.0\)</li>
    <li>\(\eta = 0.1\)</li>
</ul>

<h5>Propagation avant</h5>
<ul>
    <li>\(z^{(1)} = \begin{bmatrix} 0.1 & 0.2 \\ 0.3 & 0.4 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \begin{bmatrix} 0.1 \\ 0.2 \end{bmatrix} = \begin{bmatrix} 0.6 \\ 1.3 \end{bmatrix}\)</li>
    <li>\(a^{(1)} = \sigma(\begin{bmatrix} 0.6 \\ 1.3 \end{bmatrix}) = \begin{bmatrix} 0.6455 \\ 0.7858 \end{bmatrix}\)</li>
    <li>\(z^{(2)} = [0.5, 0.6] \begin{bmatrix} 0.6455 \\ 0.7858 \end{bmatrix} + 0.1 = 0.8941\)</li>
    <li>\(\hat{y} = 0.8941\)</li>
    <li>\(e = 1.0 - 0.8941 = 0.1059\)</li>
    <li>\(L = \frac{1}{2}(0.1059)^2 = 0.00561\)</li>
</ul>

<h5>Rétropropagation</h5>
<ul>
    <li>\(\delta^{(2)} = -(y - \hat{y}) = -0.1059\)</li>
    <li>\(\sigma'(z^{(1)}) = [0.6455(1-0.6455), 0.7858(1-0.7858)] = [0.2291, 0.1687]\)</li>
    <li>\(W^{(2)T} \cdot \delta^{(2)} = [0.5, 0.6]^T \cdot (-0.1059) = [-0.0529, -0.0635]\)</li>
    <li>\(\delta^{(1)} = [-0.0529, -0.0635] \odot [0.2291, 0.1687] = [-0.0121, -0.0107]\)</li>
</ul>

<h5>Calcul des gradients</h5>
<ul>
    <li>\(\frac{\partial L}{\partial W^{(2)}} = \delta^{(2)} \cdot (a^{(1)})^T = -0.1059 \cdot [0.6455, 0.7858] = [-0.0684, -0.0832]\)</li>
    <li>\(\frac{\partial L}{\partial b^{(2)}} = \delta^{(2)} = -0.1059\)</li>
    <li>\(\frac{\partial L}{\partial W^{(1)}} = \delta^{(1)} \cdot x^T = \begin{bmatrix} -0.0121 \\ -0.0107 \end{bmatrix} \begin{bmatrix} 1 & 2 \end{bmatrix} = \begin{bmatrix} -0.0121 & -0.0242 \\ -0.0107 & -0.0214 \end{bmatrix}\)</li>
    <li>\(\frac{\partial L}{\partial b^{(1)}} = \delta^{(1)} = \begin{bmatrix} -0.0121 \\ -0.0107 \end{bmatrix}\)</li>
</ul>

<h5>Mise à jour des paramètres</h5>
<ul>
    <li>\(W^{(2)}_{nouveau} = [0.5, 0.6] - 0.1 \cdot [-0.0684, -0.0832] = [0.5068, 0.6083]\)</li>
    <li>\(b^{(2)}_{nouveau} = 0.1 - 0.1 \cdot (-0.1059) = 0.1106\)</li>
    <li>\(W^{(1)}_{nouveau} = \begin{bmatrix} 0.1 & 0.2 \\ 0.3 & 0.4 \end{bmatrix} - 0.1 \cdot \begin{bmatrix} -0.0121 & -0.0242 \\ -0.0107 & -0.0214 \end{bmatrix} = \begin{bmatrix} 0.1012 & 0.2024 \\ 0.3011 & 0.4021 \end{bmatrix}\)</li>
    <li>\(b^{(1)}_{nouveau} = \begin{bmatrix} 0.1 \\ 0.2 \end{bmatrix} - 0.1 \cdot \begin{bmatrix} -0.0121 \\ -0.0107 \end{bmatrix} = \begin{bmatrix} 0.1012 \\ 0.2011 \end{bmatrix}\)</li>
</ul>

<h5>Vérification de l'amélioration</h5>
<p>Avec les nouveaux paramètres, recalculons \(\hat{y}\) :</p>
<ul>
    <li>\(z^{(1)} = \begin{bmatrix} 0.1012 & 0.2024 \\ 0.3011 & 0.4021 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} + \begin{bmatrix} 0.1012 \\ 0.2011 \end{bmatrix} = \begin{bmatrix} 0.6100 \\ 1.3085 \end{bmatrix}\)</li>
    <li>\(a^{(1)} = \sigma(\begin{bmatrix} 0.6100 \\ 1.3085 \end{bmatrix}) = \begin{bmatrix} 0.6477 \\ 0.7880 \end{bmatrix}\)</li>
    <li>\(z^{(2)} = [0.5068, 0.6083] \begin{bmatrix} 0.6477 \\ 0.7880 \end{bmatrix} + 0.1106 = 0.9023\)</li>
    <li>\(\hat{y} = 0.9023\)</li>
    <li>\(e = 1.0 - 0.9023 = 0.0977\)</li>
    <li>\(L = \frac{1}{2}(0.0977)^2 = 0.00477\)</li>
</ul>

<p>Nous constatons que l'erreur a diminué de 0.1059 à 0.0977 et la perte de 0.00561 à 0.00477, ce qui confirme que la rétropropagation a effectivement amélioré notre modèle.</p>

<h3>Compréhension Profonde de la Règle de Chaîne dans la Rétropropagation</h3>
<p>La rétropropagation est essentiellement une application systématique de la règle de chaîne à travers tout le réseau. Pour comprendre pleinement ce processus, analysons la dérivation complète pour un poids spécifique, disons \(w_{11}^{(1)}\) (le poids reliant l'entrée 1 au premier neurone caché).</p>

<p>Nous voulons calculer \(\frac{\partial L}{\partial w_{11}^{(1)}}\). En appliquant la règle de chaîne :</p>
<p>\[\frac{\partial L}{\partial w_{11}^{(1)}} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z^{(2)}} \cdot \frac{\partial z^{(2)}}{\partial a_1^{(1)}} \cdot \frac{\partial a_1^{(1)}}{\partial z_1^{(1)}} \cdot \frac{\partial z_1^{(1)}}{\partial w_{11}^{(1)}}\]</p>

<p>Décortiquons chaque terme :</p>
<ol>
    <li>\(\frac{\partial L}{\partial \hat{y}} = -(y - \hat{y}) = -e\)</li>
    <li>\(\frac{\partial \hat{y}}{\partial z^{(2)}} = 1\) (puisque \(\hat{y} = z^{(2)}\))</li>
    <li>\(\frac{\partial z^{(2)}}{\partial a_1^{(1)}} = w_1^{(2)}\) (le poids de la couche cachée vers la sortie)</li>
    <li>\(\frac{\partial a_1^{(1)}}{\partial z_1^{(1)}} = \sigma'(z_1^{(1)}) = \sigma(z_1^{(1)})(1 - \sigma(z_1^{(1)}))\)</li>
    <li>\(\frac{\partial z_1^{(1)}}{\partial w_{11}^{(1)}} = x_1\) (l'entrée correspondante)</li>
</ol>

<p>Ainsi :</p>
<p>\[\frac{\partial L}{\partial w_{11}^{(1)}} = (-e) \cdot 1 \cdot w_1^{(2)} \cdot \sigma'(z_1^{(1)}) \cdot x_1\]</p>

<p>Ce qui correspond exactement à :</p>
<p>\[\frac{\partial L}{\partial w_{11}^{(1)}} = \delta^{(2)} \cdot w_1^{(2)} \cdot \sigma'(z_1^{(1)}) \cdot x_1 = \delta_1^{(1)} \cdot x_1\]</p>

<p>C'est la justification mathématique du calcul des deltas que nous avons utilisé dans notre exemple numérique.</p>

<h3>Importance de la Règle de Chaîne pour la Rétropropagation</h3>
<ol>
    <li><strong>Efficacité computationnelle</strong> : Sans la règle de chaîne, nous devrions calculer chaque gradient indépendamment, ce qui serait extrêmement coûteux. La rétropropagation réutilise les calculs intermédiaires, rendant l'algorithme très efficace.</li>
    <li><strong>Propagation de l'information</strong> : La règle de chaîne permet de propager l'information sur l'erreur depuis la sortie vers l'entrée, ce qui est essentiel pour que les couches cachées puissent apprendre.</li>
    <li><strong>Généralité</strong> : La règle de chaîne s'applique à n'importe quelle composition de fonctions, ce qui rend la rétropropagation applicable à presque tous les types de réseaux de neurones.</li>
    <li><strong>Intuition géométrique</strong> : Chaque terme dans la règle de chaîne correspond à une "étape" dans le réseau, nous permettant de comprendre comment chaque composant contribue à l'erreur finale.</li>
</ol>

<h2>5. Importance pour l'Apprentissage Automatique</h2>

<h3>Optimisation et descente de gradient</h3>
<p>Le calcul vectoriel est au cœur des algorithmes d'optimisation en apprentissage automatique. La descente de gradient utilise le gradient pour minimiser une fonction de perte :</p>
<p>\[W_{nouveau} = W_{ancien} - \eta \cdot \nabla L(W_{ancien})\]</p>
<p>Où \(\eta\) est le taux d'apprentissage. Le gradient indique la direction de la plus forte augmentation de la fonction, donc nous nous déplaçons dans la direction opposée pour minimiser la perte.</p>

<h3>Points Clés à Retenir</h3>
<ol>
    <li><strong>Le gradient généralise la notion de pente aux dimensions supérieures</strong> et guide la plupart des algorithmes d'optimisation.</li>
    <li><strong>La matrice jacobienne linéarise les applications vectorielles</strong> - essentielle pour la rétropropagation.</li>
    <li><strong>La règle de chaîne est le fondement mathématique de la rétropropagation</strong> - sans elle, les réseaux de neurones profonds ne pourraient pas apprendre.</li>
    <li><strong>La géométrie visuelle construit une intuition forte</strong> : chaque dérivée raconte une histoire de mouvement.</li>
</ol>


<h2>Conclusion</h2>
<p>En maîtrisant le calcul vectoriel, vous obtiendrez non seulement la capacité à implémenter des algorithmes existants, mais aussi à concevoir de nouvelles approches et à résoudre des problèmes complexes dans le domaine de l'apprentissage automatique. Le calcul vectoriel n'est pas seulement un outil mathématique - c'est le langage qui permet de décrire comment les modèles apprennent et s'adaptent, ce qui est au cœur même de l'apprentissage automatique.</p>

<h2>Liens Utiles</h2>
<p>Pour approfondir vos connaissances et explorer des outils avancés, voici quelques ressources :</p>
<ul>
    <li><a href="https://drive.google.com/file/d/1cNnrKeiTzNR64m7A2FchGDZuLYAvtM7J/view">Mathematical foundations of Deep Learning</a></li>
    <li><a href="https://mml-book.github.io">Mathematics for Machine Learning</a></li>
    <li><a href="https://www.3blue1brown.com/#lessons">Linear Algebra and Calculus</a></li>
</ul>
<div class="music-suggestion">
    <p>Ma recommandation musicale du jour : à écouter sans modération !</p>
    <a href="https://www.youtube.com/watch?v=BiiX0rSkzWo&list=RDBiiX0rSkzWo&start_radio=1" target="_blank">Écouter sur YouTube</a>
</div>
<footer>
    <p><span class="copyleft">&copy;</span> 2025 Jonathan Suru. This work is free.</p>
</footer>
<!-- 100% privacy-first analytics -->
<script data-collect-dnt="true" async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif?collect-dnt=true" alt="" referrerpolicy="no-referrer-when-downgrade"/></noscript>
</body>
</html>